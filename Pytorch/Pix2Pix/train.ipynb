{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler,autocast\n",
    "from generator import Generator\n",
    "from Discriminator import Discriminator\n",
    "from Dataset import CustomDataset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda\")\n",
    "\n",
    "epochs=100\n",
    "batch_size=64\n",
    "lr=2e-4\n",
    "lambda_pixel=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator=Generator().to(device)\n",
    "discriminator=Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion=nn.MSELoss()\n",
    "criterion_pixelwise=nn.L1Loss()\n",
    "optim_G=optim.Adam(generator.parameters(),lr=lr)\n",
    "optim_D=optim.Adam(discriminator.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "  transforms.Resize((256,256),Image.BICUBIC),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "dataset=CustomDataset(root=\"maps/train\",transform=transform)\n",
    "loader=DataLoader(dataset,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_scaler=GradScaler()\n",
    "g_scaler=GradScaler()\n",
    "for epoch in range(epochs):\n",
    "  for i,(x,y) in enumerate(tqdm(loader,desc=f\"Epoch={epoch+1}/{epochs}\")):\n",
    "    x=x.to(device)\n",
    "    y=y.to(device)\n",
    "\n",
    "    with autocast():\n",
    "      y_fake=generator(x)\n",
    "      disc_fake=discriminator(x,y_fake.detach())\n",
    "      d_loss_fake=criterion(disc_fake,torch.zeros_like(disc_fake))\n",
    "      disc_real=discriminator(x,y)\n",
    "      d_loss_real=criterion(disc_real,torch.ones_like(disc_real))\n",
    "      d_loss=(d_loss_fake+d_loss_real)/2\n",
    "    optim_D.zero_grad()\n",
    "    d_scaler.scale(d_loss).backward()\n",
    "    d_scaler.step(optim_D)\n",
    "    d_scaler.update()\n",
    "    with autocast():\n",
    "      d_fake=discriminator(x,y_fake)\n",
    "      g_fake_loss=criterion(d_fake,torch.ones_like(d_fake))\n",
    "      l1=criterion_pixelwise(y_fake,y)*lambda_pixel\n",
    "      g_loss=g_fake_loss+l1\n",
    "    optim_G.zero_grad()\n",
    "    g_scaler.scale(g_loss).backward()\n",
    "    g_scaler.step(optim_G)\n",
    "    g_scaler.update()\n",
    "  print(f\"Epoch [{epoch+1}/{epochs}] Loss D:{d_loss.item():.4f},Loss G:{g_loss.item():.4f}\")\n",
    "  if epoch%10==0:\n",
    "    torch.save(generator.state_dict(),f\"generator.pth\")\n",
    "    torch.save(discriminator.state_dict(),f\"discriminator.pth\")\n",
    "  with torch.no_grad():\n",
    "    y_fake=generator(x)\n",
    "    x=transforms.ToPILImage()(x[2].cpu())\n",
    "    y=transforms.ToPILImage()(y[2].cpu())\n",
    "    y_fake=transforms.ToPILImage()(y_fake[2].cpu())\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.imshow(x)\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.imshow(y)\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title(\"Generated Image\")\n",
    "    plt.imshow(y_fake)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval=CustomDataset(root=\"maps/val\",transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(input_image, generated_image, target_image=None):\n",
    "    input_image = input_image.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "    generated_image = generated_image.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    " \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(input_image)\n",
    "    plt.title('Input Image')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(generated_image)\n",
    "    plt.title('Generated Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    if target_image is not None:\n",
    "        target_image = target_image.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(target_image)\n",
    "        plt.title('Target Image')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.load_state_dict(torch.load('generator.pth'))\n",
    "discriminator.load_state_dict(torch.load('discriminator.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_to_generate=5\n",
    "count=0\n",
    "for i,(x,y) in enumerate(eval):\n",
    "    if count >= num_images_to_generate:\n",
    "        break\n",
    "    x=x.to(device)\n",
    "    y=y.to(device)\n",
    "    if x.dim() == 3:\n",
    "        x = x.unsqueeze(0)\n",
    "    if y.dim() == 3:  \n",
    "        y = y.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        generated_image = generator(x)\n",
    "    display_images(x, generated_image,y)\n",
    "    count+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
