{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class critic(nn.Module):\n",
    "  def __init__(self,channel_imgs,num_classes,img_size):\n",
    "\n",
    "    super(critic,self).__init__()\n",
    "    self.img_size=img_size\n",
    "    self.critic=nn.Sequential(\n",
    "      nn.Conv2d(channel_imgs+1,64,4,2,1),\n",
    "      nn.LeakyReLU(0.2),\n",
    "      nn.Conv2d(64,128,4,2,1),\n",
    "      nn.InstanceNorm2d(128),\n",
    "      nn.LeakyReLU(0.2),\n",
    "      nn.Conv2d(128,256,4,2,1),\n",
    "      nn.InstanceNorm2d(256),\n",
    "      nn.LeakyReLU(0.2),\n",
    "      nn.Conv2d(256,512,4,2,1),\n",
    "      nn.InstanceNorm2d(512),\n",
    "      nn.LeakyReLU(0.2),\n",
    "      nn.Conv2d(512,1,4,2,0)\n",
    "    )\n",
    "    self.embed=nn.Embedding(num_classes,img_size*img_size)\n",
    "  def forward(self,x,labels):\n",
    "    embedding=self.embed(labels).view(labels.shape[0],1,self.img_size,self.img_size)\n",
    "    x=torch.cat([x,embedding],dim=1)\n",
    "    return self.critic(x)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "  def __init__(self,z_dim,channels_img,num_classes,img_size,embed_size):\n",
    "    super(Generator,self).__init__()\n",
    "    self.img_size=img_size\n",
    "    self.gen=nn.Sequential(\n",
    "      nn.ConvTranspose2d(z_dim+embed_size,1024,4,1,1,bias=False),\n",
    "      nn.BatchNorm2d(1024),\n",
    "      nn.ReLU(),\n",
    "      nn.ConvTranspose2d(1024,512,4,2,1,bias=False),\n",
    "      nn.BatchNorm2d(512),\n",
    "      nn.ReLU(),\n",
    "      nn.ConvTranspose2d(512,256,4,2,1,bias=False),\n",
    "      nn.BatchNorm2d(256),\n",
    "      nn.ReLU(),\n",
    "      nn.ConvTranspose2d(256,128,4,2,1,bias=False),\n",
    "      nn.BatchNorm2d(128),\n",
    "      nn.ReLU(),\n",
    "      nn.ConvTranspose2d(128,64,4,2,1,bias=False),\n",
    "      nn.BatchNorm2d(64),\n",
    "      nn.ReLU(),\n",
    "      nn.ConvTranspose2d(64,channels_img,4,2,1),\n",
    "      nn.Tanh()\n",
    "    )\n",
    "    self.embed=nn.Embedding(num_classes,embed_size)\n",
    "  def forward(self,x,labels):\n",
    "    embedding=self.embed(labels).unsqueeze(2).unsqueeze(3)\n",
    "    x=torch.cat([x,embedding],dim=1)\n",
    "    return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "  for m in model.modules():\n",
    "    if isinstance(m,(nn.Conv2d,nn.ConvTranspose2d,nn.BatchNorm2d)):\n",
    "      nn.init.normal_(m.weight.data,0.0,0.02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "c=5\n",
    "epochs=5\n",
    "lambda_gp=10\n",
    "image_size=64\n",
    "z_dim=100\n",
    "learning_rate=1e-4\n",
    "channel_img=1\n",
    "device=\"cuda\"\n",
    "num_classes=10\n",
    "gen_embedding=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms=transforms.Compose([\n",
    "  transforms.Resize(image_size),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize([0.5 for _ in range(channel_img)],[0.5 for _ in range(channel_img)])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=datasets.MNIST(root='./data',download=True,train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=DataLoader(datasets,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penulty(critic,real,fake,labels,device=\"cpu\"):\n",
    "  batch_size,c,h,w=real.shape\n",
    "  alpha=torch.rand((batch_size,1,1,1)).repeat(1,c,h,w).to(device)\n",
    "  interpolated_images=real*alpha+fake*(1-alpha)\n",
    "\n",
    "  mixed_scores=critic(interpolated_images,labels)\n",
    "\n",
    "  gradient=torch.autograd.grad(\n",
    "    inputs=interpolated_images,\n",
    "    outputs=mixed_scores,\n",
    "    grad_outputs=torch.ones_like(mixed_scores),\n",
    "    create_graph=True,\n",
    "    retain_graph=True\n",
    "  )[0]\n",
    "  gradient=gradient.view(gradient.shape[0],-1)\n",
    "  gradient_norm=gradient.norm(2,dim=1)\n",
    "  gradient_penulty=torch.mean((gradient_norm-1)**2)\n",
    "  return gradient_penulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen=Generator(z_dim,channel_img,num_classes,image_size,gen_embedding).to(device)\n",
    "critic=critic(channel_img,num_classes,image_size).to(device)\n",
    "initialize_weights(gen)\n",
    "initialize_weights(critic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_optim=optim.Adam(gen.parameters(),lr=learning_rate,betas=(0.0,0.9))\n",
    "critic_optim=optim.Adam(critic.parameters(),lr=learning_rate,betas=(0.0,0.9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise=torch.randn(32,z_dim,1,1).to(device)\n",
    "gen.train()\n",
    "critic.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(real_images,fake_images,epoch):\n",
    "  real_grid=torchvision.utils.make_grid(real_images[:8],normalize=True)\n",
    "  fake_grid=torchvision.utils.make_grid(fake_grid[:8],normalize=True)\n",
    "  fig,axs=plt.subplot(1,2,figsize=(12,6))\n",
    "  axs[0].imshow(real_grid.permute(1,2,0).cpu().numpy())\n",
    "  axs[0].set_title(f'Real images (Epoch {epoch})')\n",
    "  axs[0].axis('off')\n",
    "  axs[1].imshow(fake_grid.permute(1,2,1).cpu().numpy())\n",
    "  axs[1].set_title(f'Fake images (Epoch {epoch})')\n",
    "  axs[1].axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for epoch in range(epochs):\n",
    "  with tqdm(total=len(loader),desc=f\"epochs{epoch+1/{epoch}}\") as pbar:\n",
    "  for batch_idx,(real,labels) in enumerate(loader):\n",
    "    real=real.to(device)\n",
    "    cur_batch_size=real.shape[0]\n",
    "    labels=labels.to(device)\n",
    "    for _ in range(c):\n",
    "      noise=torch.rand((cur_batch_size,z_dim,1,1)).to(device)\n",
    "      fake=gen(noise,labels)\n",
    "      critic_real=critic(real,labels).reshape(-1)\n",
    "      critic_fake=critic(fake,labels).reshape(-1)\n",
    "      gp=gradient_penulty(critic,real,fake,labels,device)\n",
    "      critic_loss=(-torch.mean(real)-torch.mean(fake))+lambda_gp*gp\n",
    "      critic_optim.zero_grad()\n",
    "      critic_loss.backward(retain_graph=True)\n",
    "      critic_optim.step()\n",
    "    gen_fake=critic(fake,labels).reshape(-1)\n",
    "    gen_loss=-torch.mean(gen_fake)\n",
    "    gen_optim.zero_grad()\n",
    "    gen_loss.backward()\n",
    "    gen_optim.step()\n",
    "    pbar.update(1)\n",
    "    pbar.set_postfix(critic_loss=critic_loss.item(),Generator_loss=gen_loss.item())\n",
    "  with torch.no_grad():\n",
    "    fake_images=gen(fixed_noise)\n",
    "    show_images(real,fake_images,epoch+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
